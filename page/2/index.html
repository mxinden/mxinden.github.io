<!DOCTYPE html>
<html>
<head>
	<meta name="generator" content="Hugo 0.80.0" />
	<meta charset="utf-8" />
	<meta http-equiv="X-UA-Compatible" content="IE=edge"><title>mxinden - Homepage of Max Inden </title><meta name="viewport" content="width=device-width, initial-scale=1">
	<link rel="alternate" type="application/rss+xml" href="https://max-inden.de/index.xml" title="mxinden" />
	<meta property="og:title" content="Home" />
<meta property="og:description" content="" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://max-inden.de/" />
<meta property="og:updated_time" content="2021-07-20T00:00:00+00:00" />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Home"/>
<meta name="twitter:description" content=""/>
<link href="https://fonts.googleapis.com/css?family=Ubuntu:300,400,300italic,400italic|Raleway:200,300" rel="stylesheet">

	<link rel="stylesheet" type="text/css" media="screen" href="https://max-inden.de/css/normalize.css" />
	<link rel="stylesheet" type="text/css" media="screen" href="https://max-inden.de/css/main.css" />

	<script src="https://max-inden.de/js/feather.min.js"></script>
	
	<script src="https://max-inden.de/js/main.js"></script>
</head>

<body>
	<div class="container wrapper">
		<div class="header">
	<base href="https://max-inden.de/">
	<h1 class="site-title"><a href="https://max-inden.de/">mxinden</a></h1>
	<div class="site-description"><h2>Homepage of Max Inden</h2><nav class="nav social">
			<ul class="flat"><a href="/index.xml" title="RSS"><i data-feather="rss"></i></a><a href="https://github.com/mxinden" title="Github"><i data-feather="github"></i></a><a href="https://twitter.com/mxinden" title="Twitter"><i data-feather="twitter"></i></a></ul>
		</nav>
	</div>

	<nav class="nav">
		<ul class="flat">
			
			<li>
				<a href="/">Home</a>
			</li>
			
			<li>
				<a href="/resume/">Resume</a>
			</li>
			
			<li>
				<a href="/blog/">Blog</a>
			</li>
			
			<li>
				<a href="/talks/">Talks</a>
			</li>
			
			<li>
				<a href="/misc/">Misc</a>
			</li>
			
			<li>
				<a href="/tags">Tags</a>
			</li>
			
		</ul>
	</nav>
</div>


		<hr>
<h3 id="hi-there">Hi there,</h3>
<p>I am Max, a software developer interested in distributed systems, type theory
and consensus. Welcome to my little island on this crazy thing called <em>The
Internet</em>.</p>
<p>You might enjoy browsing through <a href="/misc">my list of resources I consider worth
sharing</a>, get some inspiration from the <a href="/blog">numerous summaries of past
reading group sessions</a> that I organize or simply scroll through <a href="/resume">my
resume</a> to see what I am up to lately.</p>
<p>You can best reach me via e-mail: <a href="mailto:mail@max-inden.de">mail@max-inden.de</a>.</p>
<p>GPG Fingerprint: <code>080694E5D36410B9C9B62185779B0E427AFE5ABB</code></p>
<hr>


		<div class="recent-posts section">
			<h2 class="section-header">
				Recent posts
			</h2>
			<div class="posts">
				
				
				
				<div class="post">
					<div class="meta">Jun 19, 2020</div>
					<a class="title" href="/blog/2020-06-19-latencies/">Know your latencies</a> &mdash;
					<span class="description">
						
						I find it helpful to know the orders of magnitude by which certain computer operations differ. Certainly it is not worth the effort to pay attention to every digit or learn these by heart, especially since they differ (slightly) across systems, but having a basic understanding of what a tiny fraction of time a CPU cycle occupies compared to sending a TCP packet is incredibly helpful whenever reasoning about systems performance.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">May 18, 2020</div>
					<a class="title" href="/blog/2020-05-18-26th-paper-club/">26th DistSys Reading Group - Cache coherence</a> &mdash;
					<span class="description">
						
						We have long been planning to cover the caching mechanisms in CPUs. As a shared knowledge base for the discussions in this session we chose the following two articles by Martin Thompson among other things known for his work on the LMAX Disruptor:
  CPU Cache Flushing Fallacy including a good overview over the different caches in modern Intel CPUs.
  Write Combining exemplifying the advanced mechanisms one can find in today&rsquo;s CPUs and how one can make use of them.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 27, 2020</div>
					<a class="title" href="/blog/2020-04-27-25th-paper-club/">25th DistSys Reading Group - Fair queuing</a> &mdash;
					<span class="description">
						
						In the session today we covered Madhavapeddi Shreedhar and George Varghese paper &ldquo;Efficient fair queuing using deficit round-robin&rdquo; [1]. While the session was not so much about the relatively simple algorithmic details of deficit-round-robin (still worth checking out) we talked about:
  Its benefits over basic FIFO queuing and thus its impact for congestion controlled traffic (tcp) compared to not congestion controlled traffic (udp).
  Its wide deployment still seen today.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 6, 2020</div>
					<a class="title" href="/blog/2020-04-06-24th-paper-club/">24th DistSys Reading Group - BBR Congestion-Based Congestion Control</a> &mdash;
					<span class="description">
						
						After a bit of a break due to current pandemic we decided to carry on and continue our meetings as virtual calls. Ignoring the usual initial hiccups and the missing whiteboard the medium worked well for us.
Topic and reading of this session was the ACM Queue article BBR: Congestion-Based Congestion Control [1], as well as the Dropbox article Evaluating BBRv2 on the Dropbox Edge Network [2].
We started off with a quick recap of the previous session covering why we need congestion control, how one can view a multi-hop connection as a single hop connection with a single bottleneck and most importantly the fact that the Internet is the largest distributed system that most of the time &ldquo;just works&rdquo; due to congestion control.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Apr 1, 2020</div>
					<a class="title" href="/blog/2020-04-01-elimination-backoff-stack-performance/">Elimination back-off stack performance</a> &mdash;
					<span class="description">
						
						I recently stumbled upon the idea of an Elimination Back-off Stack promising to be a parallel, linearizable and lock-free stack. In case you are not familiar with it, I would suggest either reading my previous post or the corresponding paper [1] itself. Being quite intrigued by the ideas of the above stack I wrote my own implementation in Rust with a little help from crossbeam.
In this post I will compare my implementation to other stack implementations.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Mar 28, 2020</div>
					<a class="title" href="/blog/2020-03-28-elimination-backoff-stack/">Elimination back-off stack</a> &mdash;
					<span class="description">
						
						Reading The Art of Multiprocessor Programming [1] I came across the Elimination Back-off Stack [2] datastructure introduced in 2004 by Danny Hendler, Nir Shavit, and Lena Yerushalmi. It promises to be a parallel lock-free stack.
How can a stack allow parallel operations without going through a single serialization point, e.g. a Mutex or an Atomic? Let&rsquo;s dive into it.
A lock-free stack A lock-free stack, also often referred to as a Treiber stack [3] due to Kent Treiber, operates on top of a lock-free linked list.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Mar 14, 2020</div>
					<a class="title" href="/blog/2020-03-14-leaving-prometheus-team/">Leaving the Prometheus team</a> &mdash;
					<span class="description">
						
						In January 2017 I joined the company CoreOS as a test-engineer helping the monitoring team and the rkt container engine team write reliable software. Eventually I joined the CoreOS' monitoring team full-time as a software engineer and ultimately was invited to be part of the upstream Prometheus team due to my contributions to the Alertmanager sub-project.
Over the next 2 years and 4 month I worked a lot on Alertmanager, e.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Feb 18, 2020</div>
					<a class="title" href="/blog/2020-02-18-23rd-paper-club/">23rd Distributed Systems Paper Club</a> &mdash;
					<span class="description">
						
						At the end of the previous session one of us suggested to dive into congestion control algorithms. This has found a greater echo, thus the 23rd session covered congestion control algorithms in general and TCP&rsquo;s Reno as well as TCP&rsquo;s Tahoe in particular.
This weeks reading was:
  Chapter 13 &ldquo;TCP Reno and Congestion Management&rdquo; from the comprehensive online book &ldquo;An Introduction to Computer Networks&rdquo; [1] from the Loyola University Chicago.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Jan 28, 2020</div>
					<a class="title" href="/blog/2020-01-28-22nd-paper-club/">22nd Distributed Systems Paper Club</a> &mdash;
					<span class="description">
						
						In the 22nd session we took a look at io_uring - a new Kernel interface for asynchronous I/O. Tyler, who is currently implementing an io_uring library in Rust [4] for his database sled [7] guided us through the concepts as well as a bunch of source code.
Tyler started off introducing the status quo of I/O interfaces within the Linux Kernel like read, pread and preadv, jumped over to asynchronous I/O like aio and eventually helped us develop a sense of what the perfect asynchronous I/O interface of the future could look like.&hellip;
						
					</span>
				</div>
				
				<div class="post">
					<div class="meta">Jan 24, 2020</div>
					<a class="title" href="/blog/2020-01-24-21st-paper-club/">21st Distributed Systems Paper Club</a> &mdash;
					<span class="description">
						
						We started the new year with a session on epidemic / gossip protocols. To decide what to read I compiled the following list of papers that I either enjoyed reading in the past, or that were recommended to me. The Swim (Scalable failure detection and membership protocol) paper won the poll.
 Das, Abhinandan, Indranil Gupta, and Ashish Motivala. &ldquo;Swim: Scalable weakly-consistent infection-style process group membership protocol.&rdquo; Proceedings International Conference on Dependable Systems and Networks.&hellip;
						
					</span>
				</div>
				
				

<ul class="pagination">
	<li class="page-item page-prev">
	
    <a href="/" class="page-link" aria-label="Previous"><span aria-hidden="true">← Prev page</span></a>
	
	</li>
	<li class="page-item page-next">
	
    <a href="/page/3/" class="page-link" aria-label="Next"><span aria-hidden="true">Next page →</span></a>
	
	</li>
</ul>


			</div>
		</div>
	</div>
	<div class="footer wrapper">
	<nav class="nav">
		<div> <a href="https://github.com/vividvilla/ezhil">Ezhil theme</a> | Built with <a href="https://gohugo.io">Hugo</a></div>
	</nav>
</div>



<script>feather.replace()</script>
</body>
</html>
